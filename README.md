**Лексический анализатор (лексер, сканер)** — это компонент компилятора или интерпретатора, предшествующий синтаксическому анализатору. Его задача — преобразование исходного текста программы (строки символов) в последовательность элементарных смысловых единиц, называемых **лексемами** (токенами). Таким образом, лексический анализатор выступает "фильтром", отделяющим синтаксический анализатор от подробностей текста, разбивая его на понятные единицы.

---

**Что такое лексемы?**

**Лексема (token)** — это минимальная синтактически значимая единица языка. Примеры лексем включают:

1. **Идентификаторы:** имена переменных, функций, классов, например `x`, `counter`, `print`.
2. **Ключевые слова:** зарезервированные имена, определённые языком, например `if`, `else`, `while`, `return`.
3. **Литералы:** константные значения, такие как числовые литералы (`42`, `3.14`), строковые литералы (`"Hello"`) или булевы (`true`, `false`).
4. **Операторы и знаки препинания (delimiters):** `+`, `-`, `*`, `/`, `=`, `;`, `,`, `(`, `)`, `{`, `}` и т.д.
5. **Комментарии:** как правило, комментарии не становятся отдельными лексемами для синтаксического анализатора, а отбрасываются, но детектируются лексером, чтобы их игнорировать.

Лексема обычно представляется парой (тип токена, значение), где тип — это класс лексемы (например, `IDENT`, `NUMBER`, `STRING`, `KEYWORD_IF`), а значение — конкретный текст, соответствующий лексеме (или же только её интерпретация, например, числовое значение).

---

**Основные задачи лексического анализатора:**

1. **Разбиение потока символов на лексемы:** Идёт последовательное чтение входного текста и группировка символов в осмысленные единицы.
2. **Пропуск несущественных элементов:** Пробелы, переводы строк и комментарии обычно не нужны синтаксическому анализатору.
3. **Категоризация лексем:** Определение типа лексемы на основе её формы. Например, последовательность цифр — это числовой литерал, определённое зарезервированное слово — ключевое слово, а последовательность букв и цифр, не являющаяся ключевым словом, может быть идентификатором.
4. **Обработка ошибок:** Если символы не составляют корректную лексему, лексер сообщает об ошибках (например, неизвестный символ или неправильный формат числа).

---

**Способы реализации лексического анализатора:**

Существует несколько подходов к реализации лексеров:

1. **Ручная реализация на основе состояний (Ad hoc методы):**  
   - **Описание:** Программист пишет код вручную, пошагово считывая символы и определяя, к какому типу лексемы они относятся.  
   - **Плюсы:**  
     - Полный контроль над процессом.  
     - Гибкость: можно реализовать любые нестандартные правила.  
   - **Минусы:**  
     - Более трудоёмко и подвержено ошибкам, особенно если язык сложен.  
     - Трудно поддерживать и расширять.

2. **Регулярные выражения и конечные автоматы:**
   - **Описание:** Основная идея — каждая категория лексем обычно описывается некоторым регулярным выражением. Затем множество этих выражений преобразуется в детерминированный конечный автомат (DFA), который осуществляет разбор входного текста.
   - **Плюсы:**  
     - Регулярные выражения — мощный и понятный способ задать шаблоны для лексем.  
     - Генераторы сканеров (например, Flex) могут автоматически сгенерировать код лексера по заданным регуляркам.
   - **Минусы:**  
     - Необходимость изучать синтаксис конкретного генератора и понимать теорию конечных автоматов.  
     - В некоторых случаях могут быть сложности с управлением предшествующими/последующими контекстами.

3. **Использование генераторов лексеров (сканнеров):**  
   - **Инструменты:** Flex (для C/C++), ANTLR (Java и другие), Lex (классический генератор для C).  
   - **Описание:** Вы описываете правила лексинга в виде набора регулярных выражений и соответствующих действий. Генератор по этим правилам создает код лексера.  
   - **Плюсы:**  
     - Ускоряет разработку: не нужно вручную писать сложный код.  
     - Легко вносить изменения: достаточно скорректировать грамматику лексера.
   - **Минусы:**  
     - Меньше контроля за внутренними деталями реализации.  
     - Потенциально сложнее отладка, когда возникают трудные ошибки.

4. **Комбинаторные подходы:**  
   - **Описание:** В функциональных языках иногда применяются парсер-комбинаторы и для лексинга, описывая набор функций-распознавателей лексем, которые можно комбинировать.  
   - **Плюсы:**  
     - Декларативный стиль, удобство модульного описания.  
   - **Минусы:**  
     - Менее эффективен при больших объёмах кода.  
     - Сложнее контролировать производительность.

5. **Специализированные библиотеки и фреймворки:**  
   - Существуют готовые решения, которые либо идут вместе с парсером (например, лексеры в ANTLR), либо предоставляют интеграцию с различными IDE, обеспечивая подсветку синтаксиса, что фактически — отдельная задача лексирования.

---

**Выбор подхода:**  
- Для простых собственных языков или конфигурационных форматов разработчик может вручную написать лексер, используя if-else конструкции или переключатели по состояниям.  
- Для промышленных языков программисты чаще полагаются на генераторы, такие как Lex/Flex вместе с Yacc/Bison или ANTLR, где грамматика языка описывается декларативно, а остальное решает генератор.

Итоговая цель лексического анализатора — из неструктурированной строки символов получить поток чётко определённых лексем, с которыми затем будет работать синтаксический анализатор.


---

**Синтаксический анализатор (парсер)** — это ключевой компонент компилятора или интерпретатора, отвечающий за преобразование последовательности входных лексем, полученных от лексического анализатора, в более высокоуровневую структуру, отражающую синтаксическую структуру программы. Итогом работы синтаксического анализатора обычно является абстрактное синтаксическое дерево (AST) или иное промежуточное представление, на основе которого впоследствии могут выполняться семантические проверки, оптимизации и генерация кода.

**Основные задачи синтаксического анализатора:**

1. **Проверка корректности структуры программы:** Парсер определяет, соответствует ли последовательность лексем грамматике языка. Если обнаруживается несоответствие, генерируются диагностические сообщения об ошибках.

2. **Построение синтаксической структуры:** При корректном соответствии коду грамматике создаётся структурированное представление, обычно в форме дерева, где узлы соответствуют синтаксическим конструкциям (выражениям, операторам, функциям и т.д.).

3. **Обеспечение основ для дальнейших этапов:** Сформированное дерево (или иная структура) упрощает дальнейшие преобразования и анализ кода — например, типизацию, оптимизацию, трансформации в промежуточный язык или генерацию машинного кода.

---

**Способы реализации синтаксических анализаторов:**

Существует множество подходов к реализации парсеров, различающихся по сложности, эффективности и удобству сопровождения. На практике особенно важны два больших класса методов: нисходящие (top-down) и восходящие (bottom-up).

1. **Рекурсивный спуск (Recursive Descent):**  
   - **Идея:** Разработчик вручную пишет набор взаимно вызывающих друг друга функций, каждая из которых соответствует нетерминалу грамматики.  
   - **Плюсы:**  
     - Простая реализация и понимание.  
     - Легко управлять логикой анализа и сообщениями об ошибках.  
   - **Минусы:**  
     - Требует, чтобы грамматика была фактически LL(1) или близка к этому. При наличии левой рекурсии или неоднозначностей приходится модифицировать грамматику или применять дополнительные техники.
     - При расширении грамматики сложнее поддерживать код.

2. **LL-анализаторы (LL(1), LL(k)):**  
   - **Идея:** Восприятие входных лексем происходит сверху-вниз, слева-направо (Left-to-right, Leftmost-derivation), при этом парсер предсказывает, какое правило применять, глядя вперед на ограниченное число токенов (1 или k токенов вперёд).  
   - **Плюсы:**  
     - Простая и понятная структура.  
     - Существенно упрощает генерацию парсера из грамматики инструментами вроде ANTLR.  
   - **Минусы:**  
     - Ограничения на грамматику, необходима её факторизация для устранения левой рекурсии.  
     - Не так гибок, как восходящие методы.

3. **LR-анализаторы (LR(0), SLR(1), LALR(1), LR(1)):**  
   - **Идея:** Анализ идёт снизу-вверх. Парсер накапливает символы и лексемы в стек, пока не сможет свернуть часть стека в нетерминал по какому-либо правилу грамматики. Решение о свёртке или сдвиге (shift/reduce) принимается на основе таблиц управления.  
   - **Плюсы:**  
     - Поддержка более широкого класса грамматик, включая многие неоднозначные конструкции.  
     - Часто эффективнее при больших и сложных языках.  
   - **Минусы:**  
     - Генерация парсеров сложнее для понимания вручную. Обычно применяют генераторы (Yacc, Bison), что упрощает работу, но усложняет отладку.  
     - Труднее напрямую контролировать структуру ошибок, возникающих при парсинге.

4. **GLR и CYK анализаторы:**  
   - **GLR (Generalized LR):** Позволяет обрабатывать неоднозначные грамматики и в теории способен работать с любыми контекстно-свободными грамматиками. Используется, если нужно парсить очень сложные или неоднозначные языки.  
   - **CYK:** Использует динамическое программирование и работает с грамматиками в нормальной форме Хомского. Это более теоретический подход, который подходит для доказательств и обработки формальных языков, но реже применяется при парсинге реальных языков программирования.

5. **Парсеры, основанные на комбинаторах (Parser Combinators):**  
   - **Идея:** В функциональных языках (Haskell, Scala) часто применяются парсер-комбинаторы — небольшие функции для разбора элементарных конструкций, которые можно комбинировать и создавать более сложные парсеры.  
   - **Плюсы:**  
     - Читаемость, возможность декларативно описывать грамматику.  
     - Легкость модификаций и расширения.  
   - **Минусы:**  
     - Менее эффективны по сравнению с генераторами таблиц LR/LL.  
     - В некоторых случаях сложнее отлаживать проблемы производительности.

---

**Инструменты и генераторы парсеров:**  
Для упрощения разработки часто применяются специальные инструменты, которые по формальному описанию грамматики генерируют код парсера:

- **Yacc/Bison (С/С++):** Генерируют LR-парсеры.
- **ANTLR (Java и другие языки):** Генерирует LL(*)-парсеры и предоставляет удобную инфраструктуру для лексинга и парсинга.
- **PEG-парсеры (Packrat parsers):** Используют Parsing Expression Grammar и позволяют реализовывать эффективные бэк-трек-парсеры без ограничений на классы грамматик, при этом обеспечивая полиномиальную асимптотику.

---

**Итог:**  
Синтаксический анализатор служит для преобразования линейной последовательности токенов в структурированное синтаксическое представление. Выбор метода реализации зависит от конкретных требований к языку, удобства сопровождения, производительности и предпочитаемой технологии. Для простых и средних по сложности языков нередко применяют LL или LALR-анализаторы с помощью генераторов, для очень специфичных или исследовательских задач — более универсальные методы (GLR, PEG), а для простейших кастомных языков или конфигурационных форматов — рекурсивный спуск или парсер-комбинаторы.